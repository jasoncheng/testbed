- name: Set fact
  ansible.builtin.set_fact:
    action: "{{ 'present' if uninstall is not defined or not uninstall else 'absent' }}"

- name: Modprobe rbd
  become: true
  ansible.builtin.command: modprobe rbd
  when: not is_centos7_pi

- name: Modprobe ceph
  become: true
  ansible.builtin.command: modprobe ceph
  when: not is_centos7_pi

- name: If require reboot
  ansible.builtin.include_role:
    name: base
    tasks_from: reboot

- name: Add repo
  kubernetes.core.helm_repository:
    name: rook-release
    repo_url: https://charts.rook.io/release
  when:
    - inventory_hostname in groups['k8sM']
    - action != 'absent'

- name: "Do {{ action }} rook-ceph operator"
  when: inventory_hostname in groups['k8sM']
  ignore_errors: true
  kubernetes.core.helm:
    create_namespace: true
    release_namespace: rook-ceph
    chart_ref: rook-release/rook-ceph
    update_repo_cache: true
    release_state: "{{ action }}"
    release_name: rook-ceph
    release_values:
      monitoring:
        enabled: true
      resources: null
      csi:
        # RBD
        enableRbdDriver: true
        enableRBDSnapshotter: true
        csiRBDProvisionerResource: null
        csiRBDPluginResource: null

        # CephFS
        enableCephfsDriver: true
        enableCephfsSnapshotter: true

        # CSI
        csiNFSProvisionerResource: null
        csiNFSPluginResource: null

- name: "Do {{ action }} rook-ceph-cluster"
  when: inventory_hostname in groups['k8sM']
  ignore_errors: true
  kubernetes.core.helm:
    create_namespace: true
    release_namespace: rook-ceph
    chart_ref: rook-release/rook-ceph-cluster
    update_repo_cache: true
    release_state: "{{ action }}"
    release_name: rook-ceph-cluster
    release_values:
      monitoring:
        enabled: true
      toolbox:
        enabled: true
      cephClusterSpec:
        removeOSDsIfOutAndSafeToRemove: true
        mon:
          allowMultiplePerNode: true
        mgr:
          allowMultiplePerNode: true
        dashboard:
          enabled: true
          ssl: false
        resources: null
        storage:
          useAllNodes: true
          useAllDevices: true
      cephObjectStores: null

- name: Deploy Ingress
  ansible.builtin.include_role:
    name: k8s.rook.ceph
    tasks_from: ingress
  when: action != 'absent'

- name: Some warning message
  ansible.builtin.debug:
    msg:
      - " [Notice] "
      - " Congrats !! Basically .. Rook-Ceph already installed, but maybe something wrong there cause rook-ceph-operator unable to finish all jobs."
      - ''
      - " If next step unable to finish, it could be OSD not ready yet or maybe your machines not powerful enough for rook-ceph-operator, it's take time..so maybe try again later."
      - " If you still unable to get admin password.."
      - " Plz describe pod/deployment/svc check and pod logs first;  below command maybe help "
      - " $ kubectl logs -f -n rook-ceph -l app=rook-ceph-operator "
      - ""
      - " Maybe there is no any disk ready for it? below command maybe help "
      - " I won't put format disk on ansible task for it's will cause you NEW DISK data lost, "
      - " So, plz do it manually(i won't take responsibility on this) when there is no any OSD pod prepare or created for a long time."
      - " Refs: https://docs.ceph.com/en/latest/ceph-volume/intro/ "
      - " $ ansible -m shell -a 'sudo sgdisk --zap-all /dev/YOU_NEW_DEVICE' INVENTORY_HOSTNAME[GROUP_NAME][all?]"
      - " $ ansible -m shell -a 'sudo dd if=/dev/zero of=/dev/YOU_NEW_DEVICE bs=1M count=100 oflag=direct,dsync'  INVENTORY_HOSTNAME[GROUP_NAME][all?]"
      - " $ kubectl rollout restart deploy -n rook-ceph rook-ceph-operator"
      - ""
      - " Or reset rook-ceph first and add more nodes into cluster, and play again "
      - " $ ansible-playbook k8s-rook-ceph-reset.yml "
  when: action != 'absent'

- name: Fetch admin password
  ansible.builtin.shell: |
    kubectl -n rook-ceph get secret rook-ceph-dashboard-password -o jsonpath="{['data']['password']}" | base64 --decode && echo
  register: result
  until: result.rc == 0 and result.stdout != ""
  retries: 18
  delay: 10
  when: action != 'absent'

- name: Show dashboard info
  ansible.builtin.debug:
    msg:
      - "Ceph Portal: https://{{ DOMAINS['ceph'] }}"
      - "user: admin"
      - "pass: {{ result.stdout }}"
  when: action != 'absent'

- name: Enable module
  ansible.builtin.include_role:
    name: k8s.rook.ceph
    tasks_from: enableRook
  when: action != 'absent'

# sgdisk -n 1:0:+500G /dev/sda -t 1:45b0969e-9b03-4f30-b4c6-b4b80ceff106 -c 1:"ceph journal"
# sgdisk -n 2:0:+500G /dev/sda -t 2:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -c 2:"ceph data"
# dd if=/dev/zero of=/dev/sda1 bs=1M count=100 oflag=direct,dsync
# dd if=/dev/zero of=/dev/sda2 bs=1M count=100 oflag=direct,dsync

# kubectl patch storageclass ceph-block -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"false"}}}'
# kubectl patch storageclass ceph-filesystem -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'